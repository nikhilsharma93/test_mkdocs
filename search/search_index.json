{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"EXAMPLES/","text":"Basic Examples (For a full set of examples look under examples ) Basic Pipeline Code Let us say you want to build a two-component pipeline. Example import numpy as np from appsci_utils.deployment.deploy import Component , Pipeline , repeator inp_image = np . random . uniform ( 0 , 1 , size = ( 256 , 256 )) # Let's say the two functions I want to use are demo1 and demo2 from the function library # Create the first Component comp1 = Component ( name = 'demo1' , func = 'demo1' ) # From the definition of demo1, we need to pass inp_image, add_value (optional), and mul_value (optional) # We can pass these as Static Component variables since they are not needed elsewhere. comp1 . static_args = dict ( inp_image = inp_image , add_value = 10 , mul_value = 100 ) # We want to get the final value of `inp_image` since that will need to be passed to demo2. So, record it. comp1 . to_record = dict ( inp_image = 'inp_image' ) # Create the second Component comp2 = Component ( name = 'demo2' , func = 'demo2' ) # From the definition of demo1, we need to pass inp_image and threshold_value. The former is a # runtime argument that comes from the output of demo1, and threshold_value is a static argument. comp2 . static_args = dict ( threshold_value = 0.5 ) comp2 . runtime_args = dict ( inp_image = comp1 . future_variable . inp_image ) # i.e Get the value, at that time in the future when this function is executed, # stored by name `inp_image` in comp1 and pass it to comp2's function (i.e demo2) # as the kwarg value for `inp_image` # We do not want to record anything for this component since we don't need any output from it. # Create a pipeline and add these components pipeline = Pipeline ( name = 'demo' ) pipeline . compile_pipeline ([ comp1 , comp2 ]) # Run pipeline . run () Output RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 15 : 54 : 02 . 948031 ][ PID 21641 ][ n_time = 0 ] [ 2019 - 04 - 11 15 : 54 : 02 . 948138 ][ PID 21641 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 54 : 02 . 948152 ][ PID 21641 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 54 : 02 . 948393 ][ PID 21641 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000151 [ 2019 - 04 - 11 15 : 54 : 02 . 948446 ][ PID 21641 ][ Comp demo2 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 54 : 02 . 948457 ][ PID 21641 ][ Comp demo2 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 54 : 02 . 948768 ][ PID 21641 ][ Comp demo2 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000212 Printing Variables Code Example comp2 . to_print = [ 'dummy_variable' ] Output RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 15 : 56 : 42 . 365138 ][ PID 21956 ][ n_time = 0 ] [ 2019 - 04 - 11 15 : 56 : 42 . 365232 ][ PID 21956 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 56 : 42 . 365248 ][ PID 21956 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 56 : 42 . 365508 ][ PID 21956 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000146 [ 2019 - 04 - 11 15 : 56 : 42 . 365544 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 56 : 42 . 365570 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 56 : 42 . 365774 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] to_print ... [ 2019 - 04 - 11 15 : 56 : 42 . 365792 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] [ to_print ] Value of dummy_variable [ 2019 - 04 - 11 15 : 56 : 42 . 365825 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] [ to_print ] 5 [ 2019 - 04 - 11 15 : 56 : 42 . 365960 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000316 # Note that you do not need to add a variable to `to_record` to print it. Saving Variables Code Just like printing variables, you can also save them. To achieve this, use the to_save attribute of a Component. It accepts a dictionary, where a (key, value) can be of two types: - (key, value) = (str, str) : In this case, provide the key with the variable you are trying to save, and provide the full save path as the value . The method to save is inferred from the extension of the save path. Currently, saving numpy files ( .npy ), and images ( .png or .jpg ) is supported. - (key, value) = (str, function) : In this case, key remains the same as above, but in value provide a python function handle that would take in the positional argument (0th position) of the value of key at runtime and would save it according to the custom method. Example def dummy_save ( var ): print ( 'I am a dummy save method; will not save anything.' + 'But I confirm to have received the variable {}' . format ( var )) comp2 . to_save = dict ( inp_image = 'test_inp_image.npy' , dummy_variable = dummy_save ) Output RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 15 : 58 : 04 . 105548 ][ PID 22064 ][ n_time = 0 ] [ 2019 - 04 - 11 15 : 58 : 04 . 105655 ][ PID 22064 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 58 : 04 . 105669 ][ PID 22064 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 58 : 04 . 105897 ][ PID 22064 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000140 [ 2019 - 04 - 11 15 : 58 : 04 . 105961 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 58 : 04 . 105972 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 58 : 04 . 106237 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Saving ... I am a dummy save method ; will not save anything . But I confirm to have received the variable 5 [ 2019 - 04 - 11 15 : 58 : 04 . 109076 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 003014 # Also, test_inp_image.npy gets saved # Note that you do not need to add a variable to `to_record` to save it. Adding Static Pipeline Variables Code In our basic example, let us say we use demo3 from the function library instead of demo2 (and as such, comp3 instead of comp2 ), and we want to use the same value for the argument add_value in both demo1 and demo3 . One way to do this is to add it as static_args in both the components. The other way is to add it as a static pipeline variable just once, and let both the components access it. Example inp_image = np . random . uniform ( 0 , 1 , size = ( 256 , 256 )) # Initialize a pipeline, and set the pipeline variable `add_value` pipeline = Pipeline ( name = 'demo' ) pipeline . add_pipeline_variable ( dict ( add_value = 5 )) comp1 = Component ( name = 'demo1' , func = 'demo1' ) comp1 . static_args = dict ( inp_image = inp_image , mul_value = 100 ) comp1 . runtime_args = dict ( add_value = pipeline . future_variable . add_value ) comp1 . to_record = dict ( inp_image = 'inp_image' ) comp3 = Component ( name = 'demo3' , func = 'demo3' ) comp3 . runtime_args = dict ( inp_image = comp1 . future_variable . inp_image , add_value = pipeline . future_variable . add_value ) # Note that `compile_pipeline` should be the last operation performed on the pipeline before # calling the `.run` on it pipeline . compile_pipeline ([ comp1 , comp3 ]) pipeline . run () Output # Outputs RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 16 : 06 : 19 . 808513 ][ PID 22861 ][ n_time = 0 ] [ 2019 - 04 - 11 16 : 06 : 19 . 808601 ][ PID 22861 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 16 : 06 : 19 . 808614 ][ PID 22861 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 16 : 06 : 19 . 808841 ][ PID 22861 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 00012 8 [ 2019 - 04 - 11 16 : 06 : 19 . 808874 ][ PID 22861 ][ Comp demo3 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 16 : 06 : 19 . 808885 ][ PID 22861 ][ Comp demo3 ][ n_time = 0 ] Running Function ... I received the add_value as : 5 [ 2019 - 04 - 11 16 : 06 : 19 . 809067 ][ PID 22861 ][ Comp demo3 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 0000 94 Advanced Examples Wrapping Pipeline inside another Pipeline Consider the case when you have a pipeline that you want to run inside a loop. A simple way to do this would be like Example for x in ... : pipeline . run ( kwargs = dict ( inp_x = x )) But if the for loop had to be part of a Component, which in turn was a part of a Pipeline, then there is a little more to do. Consider the example where you have a list of two dlkeys, and want to run a model over each of them. The inner most pipeline then looks like (get image) + (run model prediction). Example def get_image ( key , products ): dltile = dl . raster . dltile ( key ) img , _ = dl . raster . ndarray ( ... ) return locals () def model_predict ( model_path , inp_image ): model = load_model ( model_path ) output = model . predict ( inp_image ) return locals () comp0 = Component ( name = 'get_image' , func = get_image ) comp0 . static_args = dict ( products = [ 'usda:naip:rgbn:v1' ]) comp0 . to_record = dict ( img = 'out_image' ) # We do not provide any value for `key` right now since it will come from an outer pipeline at runtime. comp1 = Component ( name = 'model_predict' , func = model_predict ) comp1 . static_args = dict ( model_path = '...' ) comp1 . runtime_args = dict ( inp_image = comp0 . future_variable . out_image ) inner_pipeline = Pipeline ( name = 'inner_pipeline' ) inner_pipeline . compile_pipeline ([ comp0 , comp1 ]) # Now we need an outer pipeline that has one component that gets the keys and another component # that loops over the keys and passes them sequentially to the inner pipeline. # If required, you could append other components to the outer pipeline, and they will get executed once the # inner pipeline is done processing all the keys in the loop. def get_keys (): keys = [ '1024:0:1.0:-3:2' , '1024:0:1.0:-10:4' ] return locals () def loop_keys ( keys , pipeline ): for i in loop_keys : pipeline . run ( kwargs = dict ( key = i )) # This is where the argument `key` is getting passed to `get_image` of comp0. # Note that declaration of such a function loop_keys limits what pipeline can be used with it: # The first component of that pipeline \"should\" accept an argument for `key` return locals () comp_main0 = Component ( name = 'get_keys' , func = get_keys ) comp_main0 . to_record = dict ( keys = 'dlkeys' ) comp_main1 = Component ( name = 'loop_keys' , func = loop_keys ) comp_main1 . static_args = dict ( pipeline = inner_pipeline ) comp_main1 . runtime_args = dict ( keys = comp_main0 . future_variable . dlkeys ) outer_pipeline = Pipeline ( name = 'outer_pipeline' ) outer_pipeline . compile_pipeline ([ comp_main0 , comp_main1 ]) outer_pipeline . run () Sharing Component Variables across Pipelines In the above example , you would notice that the same model is being loaded twice inside the inner pipeline. A better way to do this is to load the model once, in the outer pipeline, and then share the variable with the corresponding component in the inner pipeline. This applies to any such use case, where sharing removes redundancy. Example # Create a component for loading the model def model_loader ( model_path ): model = load_model ( model_path ) return locals () # Modify the definition of `model_predict` in the previous example to not load the model def model_predict ( model , inp_image ): output = model . predict ( inp_image ) return locals () # Create the outer pipeline comp_main0 = ... # Same as the get_keys component above comp_main1 = Component ( name = 'model_loader' , func = model_loader ) comp_main1 . static_args = dict ( model_path =... ) comp_main1 . to_record = dict ( model = 'loaded_model' ) comp_main2 = ... # Same as the loop_keys component above (called as comp_main1 in that example) outer_pipeline . compile_pipeline ([ comp_main0 , comp_main1 , comp_main2 ]) # Create the inner pipeline comp0 = ... # Same as in the above example comp1 = Component ( name = 'model_predict' , func = model_predict ) comp1 . runtime_args = dict ( inp_image = comp0 . future_variable . out_image , model = comp_main1 . future_variable . shared_model ) inner_pipeline . compile_pipeline ([ comp0 , comp1 ]) Task Examples Some caution needs to be taken when defining pipelines that work with DLTasks. The main tricky point is that Tasks can only take a serializable function as its input. Therefore, any pipeline that you want to run within Tasks should be wrapped in a python function. Example: Wind Turbines Example Multiprocessing Examples See an example for multiprocessing within pipeline See an example for multiprocessing across pipeline","title":"Examples"},{"location":"EXAMPLES/#basic-examples","text":"(For a full set of examples look under examples )","title":"Basic Examples"},{"location":"EXAMPLES/#basic-pipeline","text":"Code Let us say you want to build a two-component pipeline. Example import numpy as np from appsci_utils.deployment.deploy import Component , Pipeline , repeator inp_image = np . random . uniform ( 0 , 1 , size = ( 256 , 256 )) # Let's say the two functions I want to use are demo1 and demo2 from the function library # Create the first Component comp1 = Component ( name = 'demo1' , func = 'demo1' ) # From the definition of demo1, we need to pass inp_image, add_value (optional), and mul_value (optional) # We can pass these as Static Component variables since they are not needed elsewhere. comp1 . static_args = dict ( inp_image = inp_image , add_value = 10 , mul_value = 100 ) # We want to get the final value of `inp_image` since that will need to be passed to demo2. So, record it. comp1 . to_record = dict ( inp_image = 'inp_image' ) # Create the second Component comp2 = Component ( name = 'demo2' , func = 'demo2' ) # From the definition of demo1, we need to pass inp_image and threshold_value. The former is a # runtime argument that comes from the output of demo1, and threshold_value is a static argument. comp2 . static_args = dict ( threshold_value = 0.5 ) comp2 . runtime_args = dict ( inp_image = comp1 . future_variable . inp_image ) # i.e Get the value, at that time in the future when this function is executed, # stored by name `inp_image` in comp1 and pass it to comp2's function (i.e demo2) # as the kwarg value for `inp_image` # We do not want to record anything for this component since we don't need any output from it. # Create a pipeline and add these components pipeline = Pipeline ( name = 'demo' ) pipeline . compile_pipeline ([ comp1 , comp2 ]) # Run pipeline . run () Output RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 15 : 54 : 02 . 948031 ][ PID 21641 ][ n_time = 0 ] [ 2019 - 04 - 11 15 : 54 : 02 . 948138 ][ PID 21641 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 54 : 02 . 948152 ][ PID 21641 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 54 : 02 . 948393 ][ PID 21641 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000151 [ 2019 - 04 - 11 15 : 54 : 02 . 948446 ][ PID 21641 ][ Comp demo2 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 54 : 02 . 948457 ][ PID 21641 ][ Comp demo2 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 54 : 02 . 948768 ][ PID 21641 ][ Comp demo2 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000212","title":"Basic Pipeline"},{"location":"EXAMPLES/#printing-variables","text":"Code Example comp2 . to_print = [ 'dummy_variable' ] Output RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 15 : 56 : 42 . 365138 ][ PID 21956 ][ n_time = 0 ] [ 2019 - 04 - 11 15 : 56 : 42 . 365232 ][ PID 21956 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 56 : 42 . 365248 ][ PID 21956 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 56 : 42 . 365508 ][ PID 21956 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000146 [ 2019 - 04 - 11 15 : 56 : 42 . 365544 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 56 : 42 . 365570 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 56 : 42 . 365774 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] to_print ... [ 2019 - 04 - 11 15 : 56 : 42 . 365792 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] [ to_print ] Value of dummy_variable [ 2019 - 04 - 11 15 : 56 : 42 . 365825 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] [ to_print ] 5 [ 2019 - 04 - 11 15 : 56 : 42 . 365960 ][ PID 21956 ][ Comp demo2 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000316 # Note that you do not need to add a variable to `to_record` to print it.","title":"Printing Variables"},{"location":"EXAMPLES/#saving-variables","text":"Code Just like printing variables, you can also save them. To achieve this, use the to_save attribute of a Component. It accepts a dictionary, where a (key, value) can be of two types: - (key, value) = (str, str) : In this case, provide the key with the variable you are trying to save, and provide the full save path as the value . The method to save is inferred from the extension of the save path. Currently, saving numpy files ( .npy ), and images ( .png or .jpg ) is supported. - (key, value) = (str, function) : In this case, key remains the same as above, but in value provide a python function handle that would take in the positional argument (0th position) of the value of key at runtime and would save it according to the custom method. Example def dummy_save ( var ): print ( 'I am a dummy save method; will not save anything.' + 'But I confirm to have received the variable {}' . format ( var )) comp2 . to_save = dict ( inp_image = 'test_inp_image.npy' , dummy_variable = dummy_save ) Output RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 15 : 58 : 04 . 105548 ][ PID 22064 ][ n_time = 0 ] [ 2019 - 04 - 11 15 : 58 : 04 . 105655 ][ PID 22064 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 58 : 04 . 105669 ][ PID 22064 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 58 : 04 . 105897 ][ PID 22064 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 000140 [ 2019 - 04 - 11 15 : 58 : 04 . 105961 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 15 : 58 : 04 . 105972 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 15 : 58 : 04 . 106237 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Saving ... I am a dummy save method ; will not save anything . But I confirm to have received the variable 5 [ 2019 - 04 - 11 15 : 58 : 04 . 109076 ][ PID 22064 ][ Comp demo2 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 003014 # Also, test_inp_image.npy gets saved # Note that you do not need to add a variable to `to_record` to save it.","title":"Saving Variables"},{"location":"EXAMPLES/#adding-static-pipeline-variables","text":"Code In our basic example, let us say we use demo3 from the function library instead of demo2 (and as such, comp3 instead of comp2 ), and we want to use the same value for the argument add_value in both demo1 and demo3 . One way to do this is to add it as static_args in both the components. The other way is to add it as a static pipeline variable just once, and let both the components access it. Example inp_image = np . random . uniform ( 0 , 1 , size = ( 256 , 256 )) # Initialize a pipeline, and set the pipeline variable `add_value` pipeline = Pipeline ( name = 'demo' ) pipeline . add_pipeline_variable ( dict ( add_value = 5 )) comp1 = Component ( name = 'demo1' , func = 'demo1' ) comp1 . static_args = dict ( inp_image = inp_image , mul_value = 100 ) comp1 . runtime_args = dict ( add_value = pipeline . future_variable . add_value ) comp1 . to_record = dict ( inp_image = 'inp_image' ) comp3 = Component ( name = 'demo3' , func = 'demo3' ) comp3 . runtime_args = dict ( inp_image = comp1 . future_variable . inp_image , add_value = pipeline . future_variable . add_value ) # Note that `compile_pipeline` should be the last operation performed on the pipeline before # calling the `.run` on it pipeline . compile_pipeline ([ comp1 , comp3 ]) pipeline . run () Output # Outputs RUNNING PIPELINE \"demo\" ... [ 2019 - 04 - 11 16 : 06 : 19 . 808513 ][ PID 22861 ][ n_time = 0 ] [ 2019 - 04 - 11 16 : 06 : 19 . 808601 ][ PID 22861 ][ Comp demo1 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 16 : 06 : 19 . 808614 ][ PID 22861 ][ Comp demo1 ][ n_time = 0 ] Running Function ... [ 2019 - 04 - 11 16 : 06 : 19 . 808841 ][ PID 22861 ][ Comp demo1 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 00012 8 [ 2019 - 04 - 11 16 : 06 : 19 . 808874 ][ PID 22861 ][ Comp demo3 ][ n_time = 0 ] Compute Starting ... [ 2019 - 04 - 11 16 : 06 : 19 . 808885 ][ PID 22861 ][ Comp demo3 ][ n_time = 0 ] Running Function ... I received the add_value as : 5 [ 2019 - 04 - 11 16 : 06 : 19 . 809067 ][ PID 22861 ][ Comp demo3 ][ n_time = 0 ] Compute Ended . Took 0 : 00 : 00 . 0000 94","title":"Adding Static Pipeline Variables"},{"location":"EXAMPLES/#advanced-examples","text":"","title":"Advanced Examples"},{"location":"EXAMPLES/#wrapping-pipeline-inside-another-pipeline","text":"Consider the case when you have a pipeline that you want to run inside a loop. A simple way to do this would be like Example for x in ... : pipeline . run ( kwargs = dict ( inp_x = x )) But if the for loop had to be part of a Component, which in turn was a part of a Pipeline, then there is a little more to do. Consider the example where you have a list of two dlkeys, and want to run a model over each of them. The inner most pipeline then looks like (get image) + (run model prediction). Example def get_image ( key , products ): dltile = dl . raster . dltile ( key ) img , _ = dl . raster . ndarray ( ... ) return locals () def model_predict ( model_path , inp_image ): model = load_model ( model_path ) output = model . predict ( inp_image ) return locals () comp0 = Component ( name = 'get_image' , func = get_image ) comp0 . static_args = dict ( products = [ 'usda:naip:rgbn:v1' ]) comp0 . to_record = dict ( img = 'out_image' ) # We do not provide any value for `key` right now since it will come from an outer pipeline at runtime. comp1 = Component ( name = 'model_predict' , func = model_predict ) comp1 . static_args = dict ( model_path = '...' ) comp1 . runtime_args = dict ( inp_image = comp0 . future_variable . out_image ) inner_pipeline = Pipeline ( name = 'inner_pipeline' ) inner_pipeline . compile_pipeline ([ comp0 , comp1 ]) # Now we need an outer pipeline that has one component that gets the keys and another component # that loops over the keys and passes them sequentially to the inner pipeline. # If required, you could append other components to the outer pipeline, and they will get executed once the # inner pipeline is done processing all the keys in the loop. def get_keys (): keys = [ '1024:0:1.0:-3:2' , '1024:0:1.0:-10:4' ] return locals () def loop_keys ( keys , pipeline ): for i in loop_keys : pipeline . run ( kwargs = dict ( key = i )) # This is where the argument `key` is getting passed to `get_image` of comp0. # Note that declaration of such a function loop_keys limits what pipeline can be used with it: # The first component of that pipeline \"should\" accept an argument for `key` return locals () comp_main0 = Component ( name = 'get_keys' , func = get_keys ) comp_main0 . to_record = dict ( keys = 'dlkeys' ) comp_main1 = Component ( name = 'loop_keys' , func = loop_keys ) comp_main1 . static_args = dict ( pipeline = inner_pipeline ) comp_main1 . runtime_args = dict ( keys = comp_main0 . future_variable . dlkeys ) outer_pipeline = Pipeline ( name = 'outer_pipeline' ) outer_pipeline . compile_pipeline ([ comp_main0 , comp_main1 ]) outer_pipeline . run ()","title":"Wrapping Pipeline inside another Pipeline"},{"location":"EXAMPLES/#sharing-component-variables-across-pipelines","text":"In the above example , you would notice that the same model is being loaded twice inside the inner pipeline. A better way to do this is to load the model once, in the outer pipeline, and then share the variable with the corresponding component in the inner pipeline. This applies to any such use case, where sharing removes redundancy. Example # Create a component for loading the model def model_loader ( model_path ): model = load_model ( model_path ) return locals () # Modify the definition of `model_predict` in the previous example to not load the model def model_predict ( model , inp_image ): output = model . predict ( inp_image ) return locals () # Create the outer pipeline comp_main0 = ... # Same as the get_keys component above comp_main1 = Component ( name = 'model_loader' , func = model_loader ) comp_main1 . static_args = dict ( model_path =... ) comp_main1 . to_record = dict ( model = 'loaded_model' ) comp_main2 = ... # Same as the loop_keys component above (called as comp_main1 in that example) outer_pipeline . compile_pipeline ([ comp_main0 , comp_main1 , comp_main2 ]) # Create the inner pipeline comp0 = ... # Same as in the above example comp1 = Component ( name = 'model_predict' , func = model_predict ) comp1 . runtime_args = dict ( inp_image = comp0 . future_variable . out_image , model = comp_main1 . future_variable . shared_model ) inner_pipeline . compile_pipeline ([ comp0 , comp1 ])","title":"Sharing Component Variables across Pipelines"},{"location":"EXAMPLES/#task-examples","text":"Some caution needs to be taken when defining pipelines that work with DLTasks. The main tricky point is that Tasks can only take a serializable function as its input. Therefore, any pipeline that you want to run within Tasks should be wrapped in a python function. Example: Wind Turbines Example","title":"Task Examples"},{"location":"EXAMPLES/#multiprocessing-examples","text":"See an example for multiprocessing within pipeline See an example for multiprocessing across pipeline","title":"Multiprocessing Examples"},{"location":"FUNC_DOCS/","text":"For documentation on functions and methods provided by the framework, look at READ THE DOCS Alternatively, you could do help ( Pipeline ) and help ( Component ) in the terminal.","title":"Functions and Methods"},{"location":"INSTALLATION/","text":"This framework does not use any libraries other than what the standard version of appsci_utils uses, with the exception that OpenCV is mandatory if you want to plot visual summaries of pipeline runs . Also make sure to use Python3.5+","title":"Installation"}]}